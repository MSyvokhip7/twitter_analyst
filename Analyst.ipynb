{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import nltk\n",
    "import json\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_stopwords = []\n",
    "all_stopwords.extend(get_stop_words(\"ukrainian\"))\n",
    "all_stopwords.extend(get_stop_words(\"english\"))\n",
    "all_stopwords.extend(get_stop_words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Добкин Михаил': '@mdobkin_ver3.0.json', 'Олександр Доній': '@oles_doniy_ver3.0.json', 'Уляна Супрун': 'dataSuprunEXT.json', 'УНА-УНСО': '@unaunso_ver3.0.json', 'Віталій Кличко': '@Vitaliy_Klychko_ver3.0.json', 'Олександра Кужель': '@KuzhelUA_ver3.0.json', 'Арсен Аваков': '@AvakovArsen_ver3.0.json', 'Наталія Королевська': '@NKorolevska_ver3.0.json', 'Сергій Одарич': '@sergiy_odarych_ver3.0.json', 'Анатолій Гриценко': '@agrytsenko_ver3.0.json', 'Іван Плачков': '@ivan_plachkov_ver3.0.json', 'Сергей Власенко': '@Sergey_Vlasenko_ver3.0.json', 'Юлія Тимошенко': '@YuliaTymoshenko_ver3.0.json', 'Арсеній Яценюк': '@Yatsenyuk_AP_ver3.0.json', 'Олександр Аронець': '@aronets_ver3.0.json', 'Андрій Парубій': '@AndriyParubiy_ver3.0.json', 'Віктор Балога': '@ViktorBaloha_ver3.0.json', 'Майкл Щур': 'dataMichaelSchur.json', 'Андрій Шевченко': '@AShevch_ver3.0.json', 'Андрій Садовий': '@AndriySadovyi_ver3.0.json', 'Іван Куліченко': '@IvanKulichenko_ver3.0.json', 'Роман Скрипін': 'dataSkrypinEXT.json', 'Євгеній Суслов': '@evgensuslov_ver3.0.json', 'Михаил Бродский': '@mihailobrodskiy_ver3.0.json', 'Олег Ляшко': 'dataOVLiashkoEXT.json', 'Олександр Турчинов': '@Turchynov_ver3.0.json', 'ВО Свобода': '@vo_svoboda_ver3.0.json', 'Павло Шеремета': 'dataSheremetaEXT.json', 'Петро Порошенко': 'dataPetroPoroshenko.json', \"В'ячеслав Кириленко\": '@KyrylenkoVyach_ver3.0.json', 'Святослав Вакарчук': 'dataVakarchukEXT.json', 'Виктор Пилипишин': '@Pylypyshyn_ver3.0.json', 'Олег Тягнибок': '@o_tiahnybok_ver3.0.json', 'ВО Батьківщина': '@Batkivshchyna_ver3.0.json', 'Петро Мельник': '@p_melnyk_ver3.0.json', 'Зорян Шкіряк': '@ZoryanShkiryak_ver3.0.json', 'Костянтин Грищенко': '@Gryshchenko_ver3.0.json', 'Михайло Саакашвілі': 'dataSaakashviliEXT.json', 'Леся Оробець': '@LesyaOrobets_ver3.0.json', 'Володимир Арієв': '@VolodymyrAriev_ver3.0.json', 'Михайло Ткач': 'dataMychailoTkachEXT.json'}\n"
     ]
    }
   ],
   "source": [
    "categories = dict()\n",
    "with open(\"list_of_JSONs.txt\", 'r', encoding='utf-8') as f:\n",
    "    for i in f.readlines():\n",
    "        if \" = \" in i:\n",
    "            tup = i.strip().split(\" = \")\n",
    "            categories[tup[0]] = tup[1]\n",
    "print(categories)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(file):\n",
    "    cur_tweets = file.split('\"][\"')\n",
    "    for i in range(len(cur_tweets)):\n",
    "#         print(cur_tweets[i])\n",
    "        # З Прем'єр-міністром Баварії Хорстом Зеєхофером говорили про збереження санкційного тиску на Москву https://t.co/r0RlPemAUH\n",
    "        cur_tweets[i] = cur_tweets[i].replace(\"\\\\n\", \"\").replace(\"'\",\"\").lower()\n",
    "        links = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', cur_tweets[i])\n",
    "        for link in links:\n",
    "            cur_tweets[i] = cur_tweets[i].replace(link, \"\")\n",
    "        cur_tweets[i] = ''.join([k for k in cur_tweets[i] if not k.isdigit()])\n",
    "        tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True) #nltk.RegexpTokenizer(r'\\w+')\n",
    "        tokens = tokenizer.tokenize(cur_tweets[i])\n",
    "        cur_tweets[i] = \" \".join([w for w in tokens if w not in all_stopwords])\n",
    "#         print(\"--\", cur_tweets[i])\n",
    "        # премєр-міністром баварії хорстом зеєхофером говорили збереження санкційного тиску москву\n",
    "\n",
    "    return cur_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_all_files(src):  # src - dict()\n",
    "    docs, labels = [], []\n",
    "    for k, v in src.items():\n",
    "        with open(\"JSONs/\" + v, 'r', encoding='utf-8') as tweets:\n",
    "            docs.append(preprocess(tweets.read()[2:]))\n",
    "            labels.append(k)\n",
    "    return docs, labels\n",
    "#         break\n",
    "all_tweets, all_labels = read_all_files(categories)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41\n"
     ]
    }
   ],
   "source": [
    "# print(all_tweets)\n",
    "print(len(all_tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Добкин Михаил', 'Олександр Доній', 'Уляна Супрун', 'УНА-УНСО', 'Віталій Кличко', 'Олександра Кужель', 'Арсен Аваков', 'Наталія Королевська', 'Сергій Одарич', 'Анатолій Гриценко', 'Іван Плачков', 'Сергей Власенко', 'Юлія Тимошенко', 'Арсеній Яценюк', 'Олександр Аронець', 'Андрій Парубій', 'Віктор Балога', 'Майкл Щур', 'Андрій Шевченко', 'Андрій Садовий', 'Іван Куліченко', 'Роман Скрипін', 'Євгеній Суслов', 'Михаил Бродский', 'Олег Ляшко', 'Олександр Турчинов', 'ВО Свобода', 'Павло Шеремета', 'Петро Порошенко', \"В'ячеслав Кириленко\", 'Святослав Вакарчук', 'Виктор Пилипишин', 'Олег Тягнибок', 'ВО Батьківщина', 'Петро Мельник', 'Зорян Шкіряк', 'Костянтин Грищенко', 'Михайло Саакашвілі', 'Леся Оробець', 'Володимир Арієв', 'Михайло Ткач']\n"
     ]
    }
   ],
   "source": [
    "print(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = [\" \".join(i) for i in all_tweets]\n",
    "# print(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer(max_features=650, analyzer=\"word\").fit(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ind = 0\n",
    "gl_tr_d, gl_te_d, gl_tr_l, gl_te_l = [], [], [], []\n",
    "for tweets in all_tweets:\n",
    "    test_size = int(0.4 * len(tweets))\n",
    "    train_size = len(tweets) - test_size\n",
    "    tr_d = [tweets[i] for i in range(train_size)]\n",
    "    te_d = [tweets[i] for i in range(test_size)]\n",
    "\n",
    "    gl_tr_d.append(\" \".join(tr_d))\n",
    "    gl_te_d.append(\" \".join(te_d))\n",
    "    gl_tr_l.append(all_labels[ind])\n",
    "    gl_te_l.append(all_labels[ind])\n",
    "    ind += 1\n",
    "#     break\n",
    "# print(gl_tr_l)\n",
    "# print(gl_tr_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = [vect.transform([\" \".join(text.split())]).toarray()[0] for text in gl_tr_d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = [vect.transform([\" \".join(text.split())]).toarray()[0] for text in gl_te_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_MNB = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_MNB.fit(train_data, gl_tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_MNB.score(train_data, gl_tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# print(gl_te_l)\n",
    "pred_MNB_test = clf_MNB.predict(test_data)\n",
    "score_MNB_test = accuracy_score(gl_te_l, pred_MNB_test)\n",
    "print(score_MNB_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_svm = svm.SVC(C=3.0, kernel=\"linear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=3.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.fit(train_data, gl_tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm.score(train_data, gl_tr_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tweet = 'Видео \\\"Дохід УЄФА від проведення Евро 2012\\\" (http://t.co/dm9o03AT) на @YouTube загружено.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['видео \" дохід уєфа проведення евро \" ( загружено .']\n"
     ]
    }
   ],
   "source": [
    "new_tweet = preprocess(new_tweet)\n",
    "print(new_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorized = [vect.transform([\" \".join(new_tweet)]).toarray()[0]]\n",
    "# vectorized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Петро Мельник'],\n",
       "      dtype='<U19')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorized\n",
    "clf_MNB.predict(vectorized)\n",
    "\n",
    "# clf_svm.score(vectorized, [\"Петро Мельник\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
